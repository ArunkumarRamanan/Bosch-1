```
> format(Sys.time(), "%a %b %d %Y %X")
[1] "Sun Oct 02 2016 05:40:13 PM"
> xgb.opt.depth(initial = 10, min_depth = 1, max_depth = 20, patience = 2, sd_effect = 0, worst_score = 0, learner = my_learner, better = max_better)

Exploring depth  10 : [00001] 0.29996863+0.01845736 (Score: 0.29996863 <<<) - best is: 10
Exploring depth  08 : [00001] 0.33579569+0.01094397 (Score: 0.33579569 <<<) - best is: 8
Exploring depth  12 : [00001] 0.28947496+0.00701535 (Score: 0.28947496    ) - best is: 8
Exploring depth  09 : [00001] 0.31810225+0.01343219 (Score: 0.31810225    ) - best is: 8
Exploring depth  07 : [00001] 0.36471040+0.04246713 (Score: 0.36471040 <<<) - best is: 7
Exploring depth  06 : [00001] 0.43734594+0.00755024 (Score: 0.43734594 <<<) - best is: 6
Exploring depth  05 : [00001] 0.43602021+0.00998621 (Score: 0.43602021    ) - best is: 6
Exploring depth  04 : [00001] 0.76249421+0.15223353 (Score: 0.76249421 <<<) - best is: 4
Exploring depth  03 : [00001] 0.86402981+0.00487468 (Score: 0.86402981 <<<) - best is: 3
Exploring depth  02 : [00001] 0.82015644+0.02454910 (Score: 0.82015644    ) - best is: 3
Exploring depth  01 : [00001] 0.81416539+0.00439485 (Score: 0.81416539    ) - best is: 3
Exploring depth  00 : 
Error in `[<-.data.frame`(`*tmp*`, i, "Score", value = numeric(0)) : 
  replacement has length zero
> sink()
Warning message:
In sink() : no sink to remove
> gc
function (verbose = getOption("verbose"), reset = FALSE) 
{
    res <- .Internal(gc(verbose, reset))
    res <- matrix(res, 2L, 7L, dimnames = list(c("Ncells", "Vcells"), 
        c("used", "(Mb)", "gc trigger", "(Mb)", "limit (Mb)", 
            "max used", "(Mb)")))
    if (all(is.na(res[, 5L]))) 
        res[, -5L]
    else res
}
<bytecode: 0x00000000088d0298>
<environment: namespace:base>
> gc()
            used   (Mb) gc trigger    (Mb)   max used    (Mb)
Ncells   4349901  232.4    6861544   366.5    5973518   319.1
Vcells 539223221 4114.0 1534912320 11710.5 2989858661 22810.9
> features <- list()
> 
> predictions1 <- numeric(1183747)
> predictions2 <- numeric(1183748)
> predictions3 <- data.frame(matrix(rep(0, 1183748*5), nrow = 1183748))
> 
> for (j in 1:5) {
+   
+   gc(verbose = FALSE)
+   dval1 <- dtrain[(1:1183747)[-folded[[j]]]]
+   gc(verbose = FALSE)
+   dval2 <- dtrain[(1:1183747)[folded[[j]]]]
+   
+   i <- 0
+   sink(file = "Laurae/20161002_xgb_fast/logs.txt", append = TRUE, split = FALSE)
+   cat("\n\n\nFold ", j, "\n\n", sep = "")
+   gc()
+   set.seed(11111)
+   try(temp_model <- xgb.train(data = dval1,
+                               nthread = 12,
+                               nrounds = 1000000,
+                               max_depth = Laurae.xgb.opt.depth.best,
+                               eta = 0.025,
+                               #gamma = 20,
+                               subsample = 1.0,
+                               colsample_bytree = 1.0,
+                               booster = "gbtree",
+                               feval = mcc_eval_nofail_fold,
+                               #eval_metric = "auc",
+                               maximize = TRUE,
+                               early_stopping_rounds = 5,
+                               objective = "binary:logistic",
+                               verbose = TRUE,
+                               prediction = TRUE,
+                               watchlist = list(train = dval1, test = dval2),
+                               base_score = 0.05
+                               # ,callbacks = list(cb.early.stop(stopping_rounds = 25,
+                               #                                maximize = TRUE,
+                               #                                verbose = TRUE))
+   )
+   )
+   sink()
+   cat("\nTime: ", format(Sys.time(), "%a %b %d %Y %X"), sep = "")
+   gc(verbose = FALSE)
+   predictions1[folded[[j]]] <- predict(temp_model, dval2, ntreelimit = temp_model$best_iteration)
+   cat("\nAverage of validation predictions: ", mean(predictions1[folded[[j]]]))
+   gc(verbose = FALSE)
+   predictions3[, j] <- predict(temp_model, dtest, ntreelimit = temp_model$best_iteration)
+   cat("\nAverage of test predictions: ", mean(predictions3[, j]))
+   predictions2 <- predictions3[, j] + predictions2
+   cat("\nAverage of rolling test predictions: ", mean(predictions2) * (5 / j))
+   gc(verbose = FALSE)
+   features[[j]] <- xgb.importance(feature_names = train@Dimnames[[2]], model = temp_model)
+   gc(verbose = FALSE)
+   cat("\nFold ", j, ": MCC=", mcc_eval_print(y_prob = predictions1[folded[[j]]], y_true = Y[folded[[j]]]), "\n", sep = "")
+   write.csv(predictions1, file = "Laurae/20161002_xgb_fast/predictions_oof.csv", row.names = FALSE)
+   write.csv(predictions3, file = "Laurae/20161002_xgb_fast/predictions_test_raw.csv", row.names = FALSE)
+   write.csv(features[[j]], file = paste("Laurae/20161002_xgb_fast/best_features", j, ".csv", sep = ""), row.names = FALSE)
+   
+ }

Time: Sun Oct 02 2016 06:21:32 PM
Average of validation predictions:  0.04890852
Average of test predictions:  0.04890868
Average of rolling test predictions:  0.2445434
Fold 1: MCC=0.8647857

Time: Sun Oct 02 2016 06:22:21 PM
Average of validation predictions:  0.04890727
Average of test predictions:  0.04890819
Average of rolling test predictions:  0.2445422
Fold 2: MCC=0.8654195

Time: Sun Oct 02 2016 06:23:08 PM
Average of validation predictions:  0.04890891
Average of test predictions:  0.04890837
Average of rolling test predictions:  0.2445421
Fold 3: MCC=0.8581711

Time: Sun Oct 02 2016 06:24:01 PM
Average of validation predictions:  0.04890697
Average of test predictions:  0.04890819
Average of rolling test predictions:  0.2445418
Fold 4: MCC=0.8720138

Time: Sun Oct 02 2016 06:24:52 PM
Average of validation predictions:  0.04890852
Average of test predictions:  0.04890849
Average of rolling test predictions:  0.2445419
Fold 5: MCC=0.8597589
> 
> predictions2 <- predictions2 / 5
> write.csv(predictions2, file = "Laurae/20161002_xgb_fast/predictions_test_mean.csv", row.names = FALSE)
> 
> 
> 
> 
> mcc_eval_pred <- function(y_prob, y_true) {
+   y_true <- y_true
+   
+   DT <- data.table(y_true = y_true, y_prob = y_prob, key = "y_prob")
+   
+   nump <- sum(y_true)
+   numn <- length(y_true) - nump
+   
+   DT[, tn_v := cumsum(y_true == 0)]
+   DT[, fp_v := cumsum(y_true == 1)]
+   DT[, fn_v := numn - tn_v]
+   DT[, tp_v := nump - fp_v]
+   DT[, tp_v := nump - fp_v]
+   DT[, mcc_v := (tp_v * tn_v - fp_v * fn_v) / sqrt((tp_v + fp_v) * (tp_v + fn_v) * (tn_v + fp_v) * (tn_v + fn_v))]
+   DT[, mcc_v := ifelse(!is.finite(mcc_v), 0, mcc_v)]
+   
+   return(DT[['y_prob']][which.max(DT[['mcc_v']])])
+   
+ }
> 
> 
> 
> temp_mcc <- numeric(5)
> best_mcc <- 0
> for (j in 1:5) {
+   
+   temp_mcc[j] <- mcc_eval_print(y_prob = predictions1[folded[[j]]], y_true = Y[folded[[j]]])
+   best_mcc <- best_mcc + 0.2 * temp_mcc[j]
+   cat("Fold ", j, ": MCC=", temp_mcc[j], " | rolling average: ", best_mcc * (5 / j), "\n", sep = "")
+   
+ }
Fold 1: MCC=0.8647857 | rolling average: 0.8647857
Fold 2: MCC=0.8654195 | rolling average: 0.8651026
Fold 3: MCC=0.8581711 | rolling average: 0.8627921
Fold 4: MCC=0.8720138 | rolling average: 0.8650975
Fold 5: MCC=0.8597589 | rolling average: 0.8640298
> cat("MCC: ", mean(temp_mcc), " + ", sd(temp_mcc), "\n", sep = "")
MCC: 0.8640298 + 0.005450054
> 
> best_mcc <- 0
> for (j in 1:5) {
+   
+   temp_mcc <- mcc_eval_pred(y_prob = predictions1[folded[[j]]], y_true = Y[folded[[j]]])
+   best_mcc <- best_mcc + 0.2 * temp_mcc
+   cat("Fold ", j, ": threshold=", temp_mcc, " | rolling average: ", best_mcc * (5 / j), "\n", sep = "")
+   
+ }
Fold 1: threshold=0.04888778 | rolling average: 0.04888778
Fold 2: threshold=0.04888795 | rolling average: 0.04888786
Fold 3: threshold=0.04888736 | rolling average: 0.04888769
Fold 4: threshold=0.04888746 | rolling average: 0.04888764
Fold 5: threshold=0.0488872 | rolling average: 0.04888755
> 
> submission1 <- fread("datasets/sample_submission.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
> submission1$Response <- as.numeric(predictions2 >= best_mcc)
> print(sum(submission1$Response == 1))
[1] 1182427
> write.csv(submission1, file = "Laurae/20161002_xgb_fast/submission1.csv", row.names = FALSE)
> 
> 
> best_mcc <- numeric(1183748)
> 
> for (j in 1:5) {
+   
+   temp_mcc <- mcc_eval_pred(y_prob = predictions1[folded[[j]]], y_true = Y[folded[[j]]])
+   best_mcc <- best_mcc + as.numeric(predictions3[, j] >= temp_mcc)
+   cat("Fold ", j, ": threshold=", temp_mcc, " | rolling average: ", mean(best_mcc) / j, "\n", sep = "")
+   
+ }
Fold 1: threshold=0.04888778 | rolling average: 0.9987709
Fold 2: threshold=0.04888795 | rolling average: 0.9987751
Fold 3: threshold=0.04888736 | rolling average: 0.9987461
Fold 4: threshold=0.04888746 | rolling average: 0.9987301
Fold 5: threshold=0.0488872 | rolling average: 0.9987252
> 
> 
> submission2 <- fread("datasets/sample_submission.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
> submission2$Response <- as.numeric(best_mcc >= 5)
> print(sum(submission2$Response == 1))
[1] 1182146
> write.csv(submission2, file = "Laurae/20161002_xgb_fast/submission2_5.csv", row.names = FALSE)
> 
> submission2 <- fread("datasets/sample_submission.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
> submission2$Response <- as.numeric(best_mcc >= 4)
> print(sum(submission2$Response == 1))
[1] 1182149
> write.csv(submission2, file = "Laurae/20161002_xgb_fast/submission2_4.csv", row.names = FALSE)
> 
> submission2 <- fread("datasets/sample_submission.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
> submission2$Response <- as.numeric(best_mcc >= 3)
> print(sum(submission2$Response == 1))
[1] 1182164
> write.csv(submission2, file = "Laurae/20161002_xgb_fast/submission2_3.csv", row.names = FALSE)
> 
> submission2 <- fread("datasets/sample_submission.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
> submission2$Response <- as.numeric(best_mcc >= 2)
> print(sum(submission2$Response == 1))
[1] 1182309
> write.csv(submission2, file = "Laurae/20161002_xgb_fast/submission2_2.csv", row.names = FALSE)
> 
> submission2 <- fread("datasets/sample_submission.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
> submission2$Response <- as.numeric(best_mcc >= 1)
> print(sum(submission2$Response == 1))
[1] 1182427
> write.csv(submission2, file = "Laurae/20161002_xgb_fast/submission2_1.csv", row.names = FALSE)
> 
> 
> submission3 <- fread("datasets/sample_submission.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
> submission3$Response <- as.numeric((submission1$Response + submission2$Response) >= 1) # 0.5 to 1
> print(sum(submission3$Response == 1))
[1] 1182427
> write.csv(submission3, file = "Laurae/20161002_xgb_fast/submission3.csv", row.names = FALSE)
> 
> 
> submission4 <- fread("datasets/sample_submission.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
> submission4$Response <- as.numeric((submission1$Response + submission2$Response) > 1) # 0.5 to 0
> print(sum(submission4$Response == 1))
[1] 1182427
> write.csv(submission4, file = "Laurae/20161002_xgb_fast/submission4.csv", row.names = FALSE)







Depth 10

[1]	train-mcc:0.281112+0.003651	test-mcc:0.299969+0.018457 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.300964+0.002749	test-mcc:0.282191+0.004973 
[3]	train-mcc:0.310311+0.002824	test-mcc:0.283197+0.005303 
[4]	train-mcc:0.321043+0.003832	test-mcc:0.281161+0.002496 
[5]	train-mcc:0.329455+0.003686	test-mcc:0.280472+0.003562 
[6]	train-mcc:0.335480+0.003433	test-mcc:0.273642+0.008379 
Stopping. Best iteration:
[1]	train-mcc:0.281112+0.003651	test-mcc:0.299969+0.018457




Depth 8

[1]	train-mcc:0.274098+0.003158	test-mcc:0.335796+0.010944 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.284397+0.004959	test-mcc:0.328559+0.002175 
[3]	train-mcc:0.294664+0.002460	test-mcc:0.310558+0.019980 
[4]	train-mcc:0.300672+0.003133	test-mcc:0.281975+0.004776 
[5]	train-mcc:0.306366+0.003557	test-mcc:0.281745+0.004693 
[6]	train-mcc:0.309204+0.002346	test-mcc:0.281283+0.006204 
Stopping. Best iteration:
[1]	train-mcc:0.274098+0.003158	test-mcc:0.335796+0.010944




Depth 12

[1]	train-mcc:0.287884+0.003320	test-mcc:0.289475+0.007015 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.308774+0.003441	test-mcc:0.282159+0.005406 
[3]	train-mcc:0.323046+0.003716	test-mcc:0.271593+0.016166 
[4]	train-mcc:0.334240+0.005788	test-mcc:0.262949+0.011005 
[5]	train-mcc:0.344966+0.005036	test-mcc:0.261912+0.009851 
[6]	train-mcc:0.352915+0.005732	test-mcc:0.264036+0.011087 
Stopping. Best iteration:
[1]	train-mcc:0.287884+0.003320	test-mcc:0.289475+0.007015




Depth 9

[1]	train-mcc:0.276686+0.002722	test-mcc:0.318102+0.013432 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.290815+0.005105	test-mcc:0.287970+0.009581 
[3]	train-mcc:0.303001+0.004471	test-mcc:0.285110+0.005188 
[4]	train-mcc:0.311177+0.004346	test-mcc:0.283040+0.005495 
[5]	train-mcc:0.317305+0.005537	test-mcc:0.281546+0.006172 
[6]	train-mcc:0.324187+0.004335	test-mcc:0.281741+0.006614 
Stopping. Best iteration:
[1]	train-mcc:0.276686+0.002722	test-mcc:0.318102+0.013432




Depth 7

[1]	train-mcc:0.276087+0.016365	test-mcc:0.364710+0.042467 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.276282+0.003104	test-mcc:0.328545+0.002195 
[3]	train-mcc:0.284620+0.002770	test-mcc:0.328086+0.002203 
[4]	train-mcc:0.291565+0.001915	test-mcc:0.327782+0.002262 
[5]	train-mcc:0.293176+0.002461	test-mcc:0.317185+0.020488 
[6]	train-mcc:0.295737+0.002605	test-mcc:0.308183+0.023420 
Stopping. Best iteration:
[1]	train-mcc:0.276087+0.016365	test-mcc:0.364710+0.042467




Depth 6

[1]	train-mcc:0.295205+0.005086	test-mcc:0.437346+0.007550 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.278563+0.014952	test-mcc:0.371598+0.044964 
[3]	train-mcc:0.272301+0.002528	test-mcc:0.328052+0.002232 
[4]	train-mcc:0.277745+0.002285	test-mcc:0.327933+0.002291 
[5]	train-mcc:0.279771+0.002589	test-mcc:0.327685+0.002229 
[6]	train-mcc:0.284401+0.002194	test-mcc:0.327456+0.002121 
Stopping. Best iteration:
[1]	train-mcc:0.295205+0.005086	test-mcc:0.437346+0.007550




Depth 5

[1]	train-mcc:0.288486+0.004085	test-mcc:0.436020+0.009986 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.282572+0.008324	test-mcc:0.422166+0.006943 
[3]	train-mcc:0.278185+0.007375	test-mcc:0.412207+0.006350 
[4]	train-mcc:0.272298+0.013495	test-mcc:0.386160+0.038574 
[5]	train-mcc:0.266218+0.004293	test-mcc:0.337137+0.002016 
[6]	train-mcc:0.266710+0.003647	test-mcc:0.336462+0.003044 
Stopping. Best iteration:
[1]	train-mcc:0.288486+0.004085	test-mcc:0.436020+0.009986




Depth 4

[1]	train-mcc:0.391078+0.055978	test-mcc:0.762494+0.152234 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.284152+0.002292	test-mcc:0.431123+0.014252 
[3]	train-mcc:0.275667+0.003683	test-mcc:0.413995+0.016295 
[4]	train-mcc:0.273372+0.005493	test-mcc:0.408803+0.010232 
[5]	train-mcc:0.264820+0.008652	test-mcc:0.389209+0.029305 
[6]	train-mcc:0.251622+0.003760	test-mcc:0.358315+0.026894 
Stopping. Best iteration:
[1]	train-mcc:0.391078+0.055978	test-mcc:0.762494+0.152234




Depth 3

[1]	train-mcc:0.425832+0.004140	test-mcc:0.864030+0.004875 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.352839+0.079036	test-mcc:0.664729+0.204423 
[3]	train-mcc:0.266968+0.002911	test-mcc:0.411572+0.010995 
[4]	train-mcc:0.267954+0.004345	test-mcc:0.411731+0.009217 
[5]	train-mcc:0.264671+0.002544	test-mcc:0.403825+0.011086 
[6]	train-mcc:0.258061+0.007274	test-mcc:0.388757+0.015891 
Stopping. Best iteration:
[1]	train-mcc:0.425832+0.004140	test-mcc:0.864030+0.004875




Depth 2

[1]	train-mcc:0.375735+0.024961	test-mcc:0.820156+0.024549 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.380599+0.024663	test-mcc:0.812834+0.022810 
[3]	train-mcc:0.305202+0.052693	test-mcc:0.566479+0.173717 
[4]	train-mcc:0.223431+0.006164	test-mcc:0.363283+0.008572 
[5]	train-mcc:0.221157+0.005016	test-mcc:0.353195+0.007784 
[6]	train-mcc:0.230943+0.013370	test-mcc:0.359262+0.018012 
Stopping. Best iteration:
[1]	train-mcc:0.375735+0.024961	test-mcc:0.820156+0.024549




Depth 1

[1]	train-mcc:0.351747+0.001465	test-mcc:0.814165+0.004395 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.363225+0.001891	test-mcc:0.805536+0.004603 
[3]	train-mcc:0.363225+0.001891	test-mcc:0.805536+0.004603 
[4]	train-mcc:0.365563+0.002272	test-mcc:0.802261+0.006911 
[5]	train-mcc:0.368487+0.001904	test-mcc:0.798682+0.005480 
[6]	train-mcc:0.338202+0.062189	test-mcc:0.712085+0.171529 
Stopping. Best iteration:
[1]	train-mcc:0.351747+0.001465	test-mcc:0.814165+0.004395




Depth 0

[1]	train-mcc:0.498944+0.000018	test-mcc:1.000000+0.000000 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.498944+0.000018	test-mcc:1.000000+0.000000 
[3]	train-mcc:0.498944+0.000018	test-mcc:1.000000+0.000000 
[4]	train-mcc:0.498944+0.000018	test-mcc:1.000000+0.000000 
[5]	train-mcc:0.498944+0.000018	test-mcc:1.000000+0.000000 
[6]	train-mcc:0.498944+0.000018	test-mcc:1.000000+0.000000 
Stopping. Best iteration:
[1]	train-mcc:0.498944+0.000018	test-mcc:1.000000+0.000000









Fold 1

[1]	train-mcc:0.217785	test-mcc:0.864786 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.218049	test-mcc:0.864074 
[3]	train-mcc:0.218787	test-mcc:0.423554 
[4]	train-mcc:0.218958	test-mcc:0.446808 
[5]	train-mcc:0.219690	test-mcc:0.445489 
[6]	train-mcc:0.226049	test-mcc:0.417049 
Stopping. Best iteration:
[1]	train-mcc:0.217785	test-mcc:0.864786




Fold 2

[1]	train-mcc:0.222328	test-mcc:0.865419 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.231956	test-mcc:0.837952 
[3]	train-mcc:0.231956	test-mcc:0.837952 
[4]	train-mcc:0.232636	test-mcc:0.407787 
[5]	train-mcc:0.233087	test-mcc:0.427498 
[6]	train-mcc:0.234031	test-mcc:0.408534 
Stopping. Best iteration:
[1]	train-mcc:0.222328	test-mcc:0.865419




Fold 3

[1]	train-mcc:0.226961	test-mcc:0.858171 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.226961	test-mcc:0.858171 
[3]	train-mcc:0.227282	test-mcc:0.854687 
[4]	train-mcc:0.233377	test-mcc:0.832702 
[5]	train-mcc:0.231084	test-mcc:0.423001 
[6]	train-mcc:0.231070	test-mcc:0.423001 
Stopping. Best iteration:
[1]	train-mcc:0.226961	test-mcc:0.858171




Fold 4

[1]	train-mcc:0.226010	test-mcc:0.872014 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.226842	test-mcc:0.869343 
[3]	train-mcc:0.227224	test-mcc:0.434212 
[4]	train-mcc:0.227564	test-mcc:0.433949 
[5]	train-mcc:0.227134	test-mcc:0.434217 
[6]	train-mcc:0.231500	test-mcc:0.408352 
Stopping. Best iteration:
[1]	train-mcc:0.226010	test-mcc:0.872014




Fold 5

[1]	train-mcc:0.223778	test-mcc:0.859759 
Multiple eval metrics are present. Will use test_mcc for early stopping.
Will train until test_mcc hasn't improved in 5 rounds.

[2]	train-mcc:0.232676	test-mcc:0.833869 
[3]	train-mcc:0.233432	test-mcc:0.831532 
[4]	train-mcc:0.233432	test-mcc:0.413570 
[5]	train-mcc:0.232413	test-mcc:0.396602 
[6]	train-mcc:0.232832	test-mcc:0.394319 
Stopping. Best iteration:
[1]	train-mcc:0.223778	test-mcc:0.859759

